# %%
import zipfile
from pathlib import Path

from langchain.prompts import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    PromptTemplate,
    SystemMessagePromptTemplate,
)
from langchain_core.messages import BaseMessage
from langchain_openai import ChatOpenAI

HERE = Path(__file__).parent
# %%
def get_flow_file_from_tfl(path: Path | str) -> str:
    """Get the JSON content from a TFL file contained in a zip archive.

    Args:
        path (Path | str): A path to the TFL file.

    Returns:
        str: The JSON content extracted from the TFL file.
    """
    with zipfile.ZipFile(path, "r") as zip_ref, zip_ref.open("flow") as file:
        json_content = file.read().decode("utf-8")
        return json_content


def get_system_prompt() -> SystemMessagePromptTemplate:
    """Load and return the system message prompt from 'system_prompt.txt'.

    Returns:
        SystemMessagePromptTemplate: The system prompt template.
    """
    with HERE.joinpath("prompts", "system_prompt.txt").open("r") as f:
        system_prompt = f.read()
    system_message_prompt = SystemMessagePromptTemplate(
        prompt=PromptTemplate(template=system_prompt, input_variables=["example_flow"])
    )
    return system_message_prompt


def get_human_prompt() -> HumanMessagePromptTemplate:
    """Load and return the human message prompt from 'prompt.txt'.

    Returns:
        HumanMessagePromptTemplate: The human prompt template.
    """
    with HERE.joinpath("prompts", "prompt.txt").open("r") as f:
        human_prompt = f.read()
    return HumanMessagePromptTemplate(prompt=PromptTemplate(template=human_prompt, input_variables=["flow_text"]))

def get_sql_text() -> str:
    """Get the sql from all the files in jaffle_shop_files/*.sql.

    Returns:
        str: The SQL prompt.
    """
    txt = ""
    for file in (HERE / "jaffle_shop_files").glob("*.sql"):
        with file.open("r") as f:
            query_txt = f.read()
        txt += f"\n\n```sql\n-- {file.stem}\n\n{query_txt}\n```"
    return txt

def run(path_to_flow_file: Path | str) -> list[BaseMessage]:
    """Convert a TFL file to messages using prompt templates.

    Args:
        path_to_flow_file (Path | str): The path to the TFL file.

    Returns:
        list[BaseMessage]: List of messages generated by the conversion process.
    """
    path_to_flow_file = Path(path_to_flow_file)
    path_to_example = HERE / "jaffle_shop_files/jaffle_shop.tfl"
    payload = [
        {
            "flow_text": get_flow_file_from_tfl(path_to_flow_file),
            "example_flow": get_flow_file_from_tfl(path_to_example),
            "sql_text": get_sql_text(),
        }
    ]

    chat_prompt_template = ChatPromptTemplate.from_messages([get_system_prompt(), get_human_prompt()])
    chat = ChatOpenAI(model="o3-mini")
    chain = chat_prompt_template | chat
    print(type(chain))
    output = chain.batch(payload)
    return output


def run_cli() -> None:
    """Run the command-line interface for converting a TFL file to markdown."""
    import argparse

    parser = argparse.ArgumentParser(description="Convert a TFL file to markdown.")
    parser.add_argument("path", type=str, help="Path to the TFL file")
    args = parser.parse_args()

    output = run(args.path)
    with Path("output.md").open("w") as f:
        f.write(str(output[0].content))


# %%

if __name__ == "__main__":
    output = run("shipment_example.tfl")
    with Path(__file__).parent.joinpath("output.md").open("w") as f:
        f.write(str(output[0].content))
